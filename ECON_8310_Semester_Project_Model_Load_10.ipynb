{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch torchvision torchaudio\n",
        "!pip install -q opencv-python-headless\n",
        "!pip install -q pillow\n",
        "!pip install -q numpy"
      ],
      "metadata": {
        "id": "3W8l07Cb7GH0"
      },
      "id": "3W8l07Cb7GH0",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Provided function to load the model || Function to process the video and draw boxes around moving baseball"
      ],
      "metadata": {
        "id": "Bw3Gmpsno6rj"
      },
      "id": "Bw3Gmpsno6rj"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "df5f995f",
      "metadata": {
        "id": "df5f995f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import xml.etree.ElementTree as ET\n",
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow   # ← this line enables cv2_imshow in Colab\n",
        "import torchvision.transforms as T\n",
        "from google.colab import files\n",
        "\n",
        "# Provided function to load the model\n",
        "def load_trained_model(weights_path, num_classes=3, device=None):\n",
        "    # Select device\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Loading model on device: {device}\")\n",
        "\n",
        "    # Recreate model architecture\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False)\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    # Load saved weights\n",
        "    state_dict = torch.load(weights_path, map_location=device)\n",
        "    model.load_state_dict(state_dict)\n",
        "\n",
        "    # Move model to device and set eval mode\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    print(f\"Model loaded successfully from '{weights_path}'\")\n",
        "    return model\n",
        "\n",
        "# Function to process the video and draw boxes around moving baseball\n",
        "def process_video(video_path, output_path, weights_path=\"fasterrcnn_moving_detector.pth\"):\n",
        "    # Load the model\n",
        "    model = load_trained_model(weights_path)\n",
        "\n",
        "    # Open the input video\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error opening video file: {video_path}\")\n",
        "        return\n",
        "\n",
        "    # Get video properties\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    orig_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    orig_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    print(f\"Original video size: {orig_width}x{orig_height}, FPS: {fps}\")\n",
        "\n",
        "    # Define resized dimensions\n",
        "    new_width = 1280\n",
        "    new_height = 720\n",
        "\n",
        "    # Create output video writer (using mp4v codec for .mp4; change to 'MOV ' if needing .mov)\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    writer = cv2.VideoWriter(output_path, fourcc, fps, (new_width, new_height))\n",
        "\n",
        "    # Device from model\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    # Preprocessing transforms\n",
        "    transform = T.Compose([\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    frame_count = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_count += 1\n",
        "        print(f\"Processing frame {frame_count}...\")\n",
        "\n",
        "        # Resize the frame\n",
        "        frame_resized = cv2.resize(frame, (new_width, new_height))\n",
        "\n",
        "        # Convert to RGB and PIL Image\n",
        "        rgb_frame = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
        "        pil_image = Image.fromarray(rgb_frame)\n",
        "\n",
        "        # Apply transforms and move to device\n",
        "        image_tensor = transform(pil_image).to(device)\n",
        "\n",
        "        # Run inference\n",
        "        with torch.no_grad():\n",
        "            predictions = model([image_tensor])[0]\n",
        "\n",
        "        # Extract predictions\n",
        "        boxes = predictions['boxes'].cpu().numpy()\n",
        "        labels = predictions['labels'].cpu().numpy()\n",
        "        scores = predictions['scores'].cpu().numpy()\n",
        "\n",
        "        # Draw boxes for moving baseball (assume label 2 = moving; adjust if needed)\n",
        "        for i in range(len(scores)):\n",
        "            if scores[i] > 0.5 and labels[i] == 2:\n",
        "                x1, y1, x2, y2 = map(int, boxes[i])\n",
        "                # Draw red rectangle (BGR color)\n",
        "                cv2.rectangle(frame_resized, (x1, y1), (x2, y2), (0, 0, 255), thickness=2)\n",
        "\n",
        "        # Write the annotated frame to output\n",
        "        writer.write(frame_resized)\n",
        "\n",
        "    # Release resources\n",
        "    cap.release()\n",
        "    writer.release()\n",
        "    print(f\"Processing complete. Output saved to {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##process_video_colab (version 2)"
      ],
      "metadata": {
        "id": "riChX8_ApzJG"
      },
      "id": "riChX8_ApzJG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "207193ae"
      },
      "source": [
        "def process_video_colab2(\n",
        "                       video_path,\n",
        "                       output_path=\"output_with_boxes_v2.mp4\",\n",
        "                       weights_path=\"fasterrcnn_moving_detector.pth\",\n",
        "                       general_conf_threshold=0.3,\n",
        "                       thrown_ball_label=3,\n",
        "                       thrown_ball_min_score=0.35): #thrown_ball_min_score to make the detection more sensitive.\n",
        "\n",
        "    # Load model (your existing function)\n",
        "    model = load_trained_model(weights_path, num_classes=3)\n",
        "    device = next(model.parameters()).device\n",
        "    print(f\"Model loaded on {device}\")\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error opening video\")\n",
        "        return\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    # Get original video dimensions\n",
        "    orig_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    orig_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Use original dimensions for output video\n",
        "    width  = orig_width\n",
        "    height = orig_height\n",
        "\n",
        "    # Video writer to save the result\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    transform = T.Compose([\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    print(\"Starting processing... We will display every frame and print detection info if a thrown ball is found.\")\n",
        "\n",
        "    frame_idx = 0\n",
        "    found_thrown_ball = False\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_idx += 1\n",
        "        # Do not resize the frame, use original\n",
        "        display_frame = frame.copy() # Use original frame for display and writing\n",
        "\n",
        "        # Prepare input (use original frame for inference as well)\n",
        "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        pil_image = Image.fromarray(rgb)\n",
        "        img_tensor = transform(pil_image).unsqueeze(0).to(device)\n",
        "\n",
        "        # Inference\n",
        "        with torch.no_grad():\n",
        "            pred = model(img_tensor)[0]\n",
        "\n",
        "        boxes  = pred['boxes'].cpu().numpy()\n",
        "        labels = pred['labels'].cpu().numpy()\n",
        "        scores = pred['scores'].cpu().numpy()\n",
        "\n",
        "        thrown_ball_detections_this_frame = []\n",
        "\n",
        "        for i, (box, label, score) in enumerate(zip(boxes, labels, scores)):\n",
        "            # Apply general confidence threshold for drawing all boxes\n",
        "            if score > general_conf_threshold:\n",
        "                x1, y1, x2, y2 = map(int, box)\n",
        "\n",
        "                color = (0, 255, 0) # Default green for other detections\n",
        "                label_text = f\"Class {label} ({score:.2f})\"\n",
        "\n",
        "                if label == thrown_ball_label:\n",
        "                    color = (0, 0, 255) # Red for thrown ball\n",
        "                    if score > thrown_ball_min_score:\n",
        "                        thrown_ball_detections_this_frame.append((box, score))\n",
        "                        found_thrown_ball = True\n",
        "\n",
        "                # Draw rectangle and put text for all confident detections\n",
        "                cv2.rectangle(display_frame, (x1, y1), (x2, y2), color, 3)\n",
        "                cv2.putText(display_frame, label_text, (x1, y1-8),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
        "\n",
        "        # Display every frame\n",
        "        cv2_imshow(display_frame)\n",
        "\n",
        "        # Print detection info only if a thrown ball is found in this frame\n",
        "        if thrown_ball_detections_this_frame:\n",
        "            # Get max score for the thrown ball label in this frame\n",
        "            max_thrown_ball_score = max([s for _, s in thrown_ball_detections_this_frame] or [0])\n",
        "            print(f\"Frame {frame_idx:4d} → Thrown ball (Class {thrown_ball_label}) detected with confidence: {max_thrown_ball_score:.3f}\")\n",
        "            print(\"-\" * 60)\n",
        "\n",
        "        # Always write frame to output video\n",
        "        writer.write(display_frame)\n",
        "\n",
        "    cap.release()\n",
        "    writer.release()\n",
        "    print(f\"\\nFinished! Video saved as → {output_path}\")\n",
        "    if found_thrown_ball:\n",
        "        print(\"Thrown ball (Class 2) successfully detected in some frames!\")\n",
        "    else:\n",
        "        print(\"Warning: No confident thrown ball (Class 2) found with the given thresholds. Try lowering `thrown_ball_min_score` or check if `thrown_ball_label` is correct.\")"
      ],
      "id": "207193ae",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82c1b909",
        "outputId": "df1a8fbc-5db2-4fa0-ef4e-8625d8875612",
        "collapsed": true
      },
      "source": [
        "# Example call for the new function\n",
        "process_video_colab2(\n",
        "    video_path=\"IMG_000.mov\",\n",
        "    output_path=\"IMG.Box.mp4\",\n",
        "    general_conf_threshold=0.15,  # General threshold for any detection\n",
        "    thrown_ball_label=2,          # class for the 'thrown ball'\n",
        "    thrown_ball_min_score=0.15    # Specific confidence for the thrown ball\n",
        ")"
      ],
      "id": "82c1b909",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model on device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully from 'fasterrcnn_moving_detector.pth'\n",
            "Model loaded on cpu\n",
            "Error opening video\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}